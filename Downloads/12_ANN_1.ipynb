{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e79ae388",
      "metadata": {
        "id": "e79ae388",
        "outputId": "89bcc59d-9271-4a90-eaf8-00fa84d3faf9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 1s 0us/step\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "mnist = keras.datasets.mnist\n",
        "(x_train_full, y_train_full),(x_test, y_test) = mnist.load_data()\n",
        "#The dataset is structured as a tuple of NumPy arrays: x training images, y training labels, and x test images, y test labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ac44742",
      "metadata": {
        "id": "6ac44742",
        "outputId": "9aa1292c-0b2e-44d0-8fe6-5b16e7e289d1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x22991c4ef40>"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.imshow(x_train_full[2])\n",
        "#It will show the 3rd training image as python indexing starts with 0.\n",
        "#perform data normalization so that all input values are between 0 and 1. \n",
        "#Since a grayscale image has pixel values of 0 to 255, we divide each pixel by 255. \n",
        "#Data normalization is necessary to reduce data redundancy and improve data integrity. \n",
        "#It makes sure your data is the same throughout your project."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2ede1fe",
      "metadata": {
        "id": "a2ede1fe"
      },
      "outputs": [],
      "source": [
        "x_train_norm = x_train_full/255.\n",
        "x_test_norm = x_test/255.\n",
        "\n",
        "x_valid, x_train = x_train_norm[:5000], x_train_norm[5000:]\n",
        "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
        "\n",
        "x_test = x_test_norm\n",
        "\n",
        "#Training data are fed after each training in an epoch. \n",
        "#An epoch is when the entire training dataset passes through the neural network once. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b22e945",
      "metadata": {
        "id": "7b22e945"
      },
      "outputs": [],
      "source": [
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "#42 is used as random seed in ML"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0871ae9b",
      "metadata": {
        "id": "0871ae9b"
      },
      "outputs": [],
      "source": [
        "model = keras.models.Sequential()\n",
        "\n",
        "model.add(keras.layers.Flatten(input_shape=[28,28]))\n",
        "model.add(keras.layers.Dense(300, activation=\"relu\"))\n",
        "model.add(keras.layers.Dense(100, activation=\"relu\"))\n",
        "model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
        "# 1 flatten layer as the input layer\n",
        "# 2 dense relu layers as hidden layers \n",
        "# a dense softmax layer as the output layer\n",
        "\n",
        "#A flattening layer flattens the input to a single-column array. It prepares the input data for the next dense layers. \n",
        "#a dense layer is a layer of parallel perceptrons.\n",
        "\n",
        "# relu is used on hidden layers\n",
        "#sigmoid and softmax are used for output. \n",
        "#Softmax is often used as the activation for the last layer of a classification network because the result could be interpreted as a probability distribution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a8bc412",
      "metadata": {
        "id": "0a8bc412",
        "outputId": "cd9f741e-1115-4e64-d0d7-1a7bc5e33f19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten (Flatten)           (None, 784)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 300)               235500    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 100)               30100     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                1010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 266,610\n",
            "Trainable params: 266,610\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()\n",
        "#function shows the number of parameters in each layer, how the output shape changes, \n",
        "#and the total amount of parameters to be trained."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de30da1a",
      "metadata": {
        "id": "de30da1a"
      },
      "outputs": [],
      "source": [
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=\"sgd\",\n",
        "              metrics=[\"accuracy\"])\n",
        "#sgd means stochastic gradient descent – a type of gradient descent that only uses a single training example per epoch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "090de173",
      "metadata": {
        "id": "090de173",
        "outputId": "aee42077-5fe6-4dc8-8a2d-877794be1c54"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "1719/1719 [==============================] - 3s 2ms/step - loss: 0.6196 - accuracy: 0.8405 - val_loss: 0.3103 - val_accuracy: 0.9120\n",
            "Epoch 2/30\n",
            "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2953 - accuracy: 0.9151 - val_loss: 0.2473 - val_accuracy: 0.9304\n",
            "Epoch 3/30\n",
            "1719/1719 [==============================] - 3s 1ms/step - loss: 0.2430 - accuracy: 0.9302 - val_loss: 0.2060 - val_accuracy: 0.9426\n",
            "Epoch 4/30\n",
            "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2076 - accuracy: 0.9407 - val_loss: 0.1823 - val_accuracy: 0.9494\n",
            "Epoch 5/30\n",
            "1719/1719 [==============================] - 2s 1ms/step - loss: 0.1811 - accuracy: 0.9485 - val_loss: 0.1645 - val_accuracy: 0.9540\n",
            "Epoch 6/30\n",
            "1719/1719 [==============================] - 3s 1ms/step - loss: 0.1603 - accuracy: 0.9543 - val_loss: 0.1483 - val_accuracy: 0.9602\n",
            "Epoch 7/30\n",
            "1719/1719 [==============================] - 2s 1ms/step - loss: 0.1431 - accuracy: 0.9597 - val_loss: 0.1367 - val_accuracy: 0.9632\n",
            "Epoch 8/30\n",
            "1719/1719 [==============================] - 3s 2ms/step - loss: 0.1292 - accuracy: 0.9632 - val_loss: 0.1294 - val_accuracy: 0.9638\n",
            "Epoch 9/30\n",
            "1719/1719 [==============================] - 3s 2ms/step - loss: 0.1174 - accuracy: 0.9673 - val_loss: 0.1183 - val_accuracy: 0.9670\n",
            "Epoch 10/30\n",
            "1719/1719 [==============================] - 3s 2ms/step - loss: 0.1077 - accuracy: 0.9696 - val_loss: 0.1091 - val_accuracy: 0.9692\n",
            "Epoch 11/30\n",
            "1719/1719 [==============================] - 3s 1ms/step - loss: 0.0988 - accuracy: 0.9721 - val_loss: 0.1050 - val_accuracy: 0.9694\n",
            "Epoch 12/30\n",
            "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0911 - accuracy: 0.9745 - val_loss: 0.1006 - val_accuracy: 0.9708\n",
            "Epoch 13/30\n",
            "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0843 - accuracy: 0.9762 - val_loss: 0.0948 - val_accuracy: 0.9726\n",
            "Epoch 14/30\n",
            "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0781 - accuracy: 0.9781 - val_loss: 0.0921 - val_accuracy: 0.9736\n",
            "Epoch 15/30\n",
            "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0726 - accuracy: 0.9795 - val_loss: 0.0878 - val_accuracy: 0.9720\n",
            "Epoch 16/30\n",
            "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0677 - accuracy: 0.9807 - val_loss: 0.0860 - val_accuracy: 0.9738\n",
            "Epoch 17/30\n",
            "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0632 - accuracy: 0.9821 - val_loss: 0.0835 - val_accuracy: 0.9754\n",
            "Epoch 18/30\n",
            "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0592 - accuracy: 0.9837 - val_loss: 0.0799 - val_accuracy: 0.9768\n",
            "Epoch 19/30\n",
            "1719/1719 [==============================] - 3s 1ms/step - loss: 0.0555 - accuracy: 0.9850 - val_loss: 0.0782 - val_accuracy: 0.9764\n",
            "Epoch 20/30\n",
            "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0520 - accuracy: 0.9860 - val_loss: 0.0774 - val_accuracy: 0.9770\n",
            "Epoch 21/30\n",
            "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0488 - accuracy: 0.9868 - val_loss: 0.0735 - val_accuracy: 0.9784\n",
            "Epoch 22/30\n",
            "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0458 - accuracy: 0.9878 - val_loss: 0.0743 - val_accuracy: 0.9782\n",
            "Epoch 23/30\n",
            "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0432 - accuracy: 0.9883 - val_loss: 0.0756 - val_accuracy: 0.9770\n",
            "Epoch 24/30\n",
            "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0404 - accuracy: 0.9894 - val_loss: 0.0727 - val_accuracy: 0.9772\n",
            "Epoch 25/30\n",
            "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0384 - accuracy: 0.9900 - val_loss: 0.0708 - val_accuracy: 0.9790\n",
            "Epoch 26/30\n",
            "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0360 - accuracy: 0.9911 - val_loss: 0.0681 - val_accuracy: 0.9798\n",
            "Epoch 27/30\n",
            "1719/1719 [==============================] - 3s 1ms/step - loss: 0.0340 - accuracy: 0.9915 - val_loss: 0.0673 - val_accuracy: 0.9808\n",
            "Epoch 28/30\n",
            "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0321 - accuracy: 0.9922 - val_loss: 0.0692 - val_accuracy: 0.9800\n",
            "Epoch 29/30\n",
            "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0300 - accuracy: 0.9932 - val_loss: 0.0676 - val_accuracy: 0.9794\n",
            "Epoch 30/30\n",
            "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0285 - accuracy: 0.9935 - val_loss: 0.0673 - val_accuracy: 0.9800\n"
          ]
        }
      ],
      "source": [
        "model_history = model.fit(x_train,y_train,epochs=30,validation_data=(x_valid,y_valid))\n",
        "#accuracy = 99% using our test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd200b1c",
      "metadata": {
        "id": "cd200b1c",
        "outputId": "ce44f6cb-f5c1-4d9b-bd67-4d4c935c32e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 14ms/step\n"
          ]
        }
      ],
      "source": [
        "x_sample = x_test[:5]\n",
        "y_probability = model.predict(x_sample)\n",
        "#took 5 images – index 0 to 4, and feed them to model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac6325ab",
      "metadata": {
        "id": "ac6325ab",
        "outputId": "05156012-69ff-47b7-8cd2-1afbba84e284"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_probability.round()\n",
        "#returns the probability of the image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c454df8",
      "metadata": {
        "id": "9c454df8",
        "outputId": "e603441e-15bb-40fb-a831-fe127be4e2b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 13ms/step\n"
          ]
        }
      ],
      "source": [
        "y_predict = model.predict(x_sample)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2d0ed62",
      "metadata": {
        "id": "f2d0ed62"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "name": "12 ANN_1.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}